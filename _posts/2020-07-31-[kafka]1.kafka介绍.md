---
layout: post
title:  "[kafka]1.kafka介绍"
date:   2020-07-31 17:02
tags: kafka
color: rgb(255,90,90)
cover: '../coverimages/kafka.jpg'
---

**介绍**
> Apache Kafka是 一个分布式流处理平台

**topic 和 日志**
> topic 就是数据主题 ，是数据记录发布的地方。kafka中的topic是多订阅者模式，一个topic可以被多个消费者订阅，对于每一个topic，kafka集群都会维护一个分区日志，如下图:


![enter description here](https://raw.githubusercontent.com/LazystudentCH/blogImage/master/2020/7/31/[kafka]1.kafka介绍/1596183463753.png)

> 每一个分区有序且不可变的结果记录集，并且不断追加的log文件。分区中的每一个记录都会分配一个ID号来标识顺序，我们把这个叫做offset，offset可以用来标识分区中的唯一一条记录

> kafka会保存所有的发布记录，无论这些消息是否被消费，同时可以通过一个参数来配置保留的期限。例如：保留期限设置为两天，一条记录发布之后的两天内，可以随时被消费，两天后这条记录会被抛弃并且会释放磁盘空间。kafka的性能和数据大小无关，所以可以长时间存储数据。

> 事实上，在每一个消费者中唯一保存的元数据是offset（偏移量）即消费在log中的位置，kafka的消费其实是根据offset来读取数据，读完一条数据offer往后移。所以，消费者可以采取任意的顺序来消费数据。例如，两天前消费过的数据，可以在现在将offset往回移动，从而重新消费过去的数据

![enter description here](https://raw.githubusercontent.com/LazystudentCH/blogImage/master/2020/7/31/[kafka]1.kafka介绍/1596184915735.png)

> 这些细节说明，kafka的消费者是非常廉价的，消费者数量的增加或者减少，对集群或者其他消费者是没有多大影响的。比如你可以使用一些命令来直接获取数据，例如tail之类的，并不会影响其他消费者来消费数据


> 日志中的分区，有如下几个用途，第一，当日志的数量超过了单台服务器的限制，允许日志进行扩展。每个单独的分区都必须受限于主机的文件限制，不过一个主题可能有多个分区，因此可以处理无限量的数据

**分布式**
> 日志的分区在kafka的集群的服务器上，每个服务器在处理数据和请求时，共享这些分区。