---
layout: post
title:  "[kafka]3.架构深入"
date:   2020-08-04 12:37
tags: kafka
color: rgb(255,90,90)
cover: '../coverimages/kafka.jpg'
---

# 架构深入

**kafka工作流程以及文件存储**
![enter description here](https://raw.githubusercontent.com/LazystudentCH/blogImage/master/2020/8/3/[kafka]3.架构深入/1596446484099.png)

> kafka中的消息都是以topic进行分类的，生产者生产消息，消费者消费消息，都是面向topic的。
> topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是producer生产的数据。Producer生产的数据会被不断的追加到该log文件的末端，且每条数据都有自己的offset。消费者组的每个消费者，都会时实记录自己消费到了哪个offset，以便出错时，从上次的位置继续消费。

![enter description here](https://raw.githubusercontent.com/LazystudentCH/blogImage/master/2020/8/3/[kafka]3.架构深入/1596451806552.png)

> 由于生产者会不断追加日志到log文件末尾，为了防止log文件过大导致数据定位效率低下，kafka采用了索引和分片的机制，将每个partition分解为多个segment(部分)。每个segment对应两个文件，".inde"和".log"文件，这些文件位于一个文件夹下，该文件夹的命名规则为topic名称+分区号。例如，first这个topic有三个分区，则其对应的文件夹为first-0,first-1,first-2。

![enter description here](https://raw.githubusercontent.com/LazystudentCH/blogImage/master/2020/8/3/[kafka]3.架构深入/1596452354105.png)