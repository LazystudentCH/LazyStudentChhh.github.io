---
layout: post
title:  "[kafka]3.架构深入"
date:   2020-08-04 12:37
tags: kafka
color: rgb(255,90,90)
cover: '../coverimages/kafka.jpg'
---

# 架构深入

**kafka工作流程以及文件存储**
![enter description here](https://raw.githubusercontent.com/LazystudentCH/blogImage/master/2020/8/3/[kafka]3.架构深入/1596446484099.png)

> kafka中的消息都是以topic进行分类的，生产者生产消息，消费者消费消息，都是面向topic的。
> topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是producer生产的数据。Producer生产的数据会被不断的追加到该log文件的末端，且每条数据都有自己的offset。消费者组的每个消费者，都会时实记录自己消费到了哪个offset，以便出错时，从上次的位置继续消费。

![enter description here](https://raw.githubusercontent.com/LazystudentCH/blogImage/master/2020/8/3/[kafka]3.架构深入/1596451806552.png)

> 由于生产者会不断追加日志到log文件末尾，为了防止log文件过大导致数据定位效率低下，kafka采用了索引和分片的机制，将每个partition分解为多个segment(部分)。每个segment对应两个文件，".inde"和".log"文件，这些文件位于一个文件夹下，该文件夹的命名规则为topic名称+分区号。例如，first这个topic有三个分区，则其对应的文件夹为first-0,first-1,first-2。一个log文件默认最大为1g

![enter description here](https://raw.githubusercontent.com/LazystudentCH/blogImage/master/2020/8/3/[kafka]3.架构深入/1596452354105.png)

**查找数据**
> log文件只存当前分片的某个segment数据，而index文件存当前分片的某个segment索引
> log文件和索引文件的命名方式都是以当前最小偏移量来命名的（上一个文件的最大偏移量+1）
> 查找数据过程如下：
> 1.根据之前消费的偏移量，用二分法，查找出目标index文件
> 2.因为index中存的都是数据的开始偏移量以及数据长度和一些其他的数据（每一条记录长度固定），所以，可以快速的用 Nx固定长度（N代表第几条数据） 的方式快速获取到开始偏移量和数据长度
> 3.拿到初始偏移量和数据长度，直接去对应的log文件中取出数据

![enter description here](https://raw.githubusercontent.com/LazystudentCH/blogImage/master/2020/8/3/[kafka]3.架构深入/1596466171977.png)