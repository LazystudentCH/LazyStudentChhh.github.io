---
layout: post
title:  "[kafka]3.架构深入"
date:   2020-08-04 12:37
tags: kafka
color: rgb(255,90,90)
cover: '../coverimages/kafka.jpg'
---

# 架构深入

**kafka工作流程以及文件存储**
![enter description here](https://raw.githubusercontent.com/LazystudentCH/blogImage/master/2020/8/3/[kafka]3.架构深入/1596446484099.png)

> kafka中的消息都是以topic进行分类的，生产者生产消息，消费者消费消息，都是面向topic的。
> topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是producer生产的数据。Producer生产的数据会被不断的追加到该log文件的末端，且每条数据都有自己的offset。消费者组的每个消费者，都会时实记录自己消费到了哪个offset，以便出错时，从上次的位置继续消费。

![enter description here](https://raw.githubusercontent.com/LazystudentCH/blogImage/master/2020/8/3/[kafka]3.架构深入/1596451806552.png)

> 由于生产者会不断追加日志到log文件末尾，为了防止log文件过大导致数据定位效率低下，kafka采用了索引和分片的机制，将每个partition分解为多个segment(部分)。每个segment对应两个文件，".inde"和".log"文件，这些文件位于一个文件夹下，该文件夹的命名规则为topic名称+分区号。例如，first这个topic有三个分区，则其对应的文件夹为first-0,first-1,first-2。一个log文件默认最大为1g

![enter description here](https://raw.githubusercontent.com/LazystudentCH/blogImage/master/2020/8/3/[kafka]3.架构深入/1596452354105.png)

**查找数据**
> log文件只存当前分片的某个segment数据，而index文件存当前分片的某个segment索引
> log文件和索引文件的命名方式都是以当前最小偏移量来命名的（上一个文件的最大偏移量+1）
> 查找数据过程如下：
> 1.根据之前消费的偏移量，用二分法，查找出目标index文件
> 2.因为index中存的都是数据的开始偏移量以及数据长度和一些其他的数据（每一条记录长度固定），所以，可以快速的用 Nx固定长度（N代表第几条数据） 的方式快速获取到开始偏移量和数据长度
> 3.拿到初始偏移量和数据长度，直接去对应的log文件中取出数据

![enter description here](https://raw.githubusercontent.com/LazystudentCH/blogImage/master/2020/8/3/[kafka]3.架构深入/1596466171977.png)

**分区的原因**
> 1.提高可扩展性
> 2.提高高并发，因为能以partition为单位读写了

**分区的原则**
![enter description here](https://raw.githubusercontent.com/LazystudentCH/blogImage/master/2020/8/6/[kafka]3.架构深入/1596725732020.png)

> 1.第一种情况，指定了partition，直接发到这个partition
> 2.没有指定partition，但是有key的情况下，将key做hash 然后余上partition数量，得到的值就是即将发送到的partition
> 3. 既没有partition，也没有key ， 生成一个随机数，余上partition的数量，然后轮询

**可靠性保证**
> 为保证producer生产数据的可靠性，topic每个分片收到producer的数据后，都需要返回一个ack，如果producer收到ack，就会发送下一轮数据，否则重新发送数据

![enter description here](https://raw.githubusercontent.com/LazystudentCH/blogImage/master/2020/8/8/[kafka]3.架构深入/1596855934146.png)

![enter description here](https://raw.githubusercontent.com/LazystudentCH/blogImage/master/2020/8/8/[kafka]3.架构深入/1596855955561.png)

> kafka选择了第二种，全部完成同步，才发送ack，原因如下：
> 1.为了容忍n个节点的故障，第一种需要2n+1的副本，而第二种只需要n个
> 2.虽然第二种方案网络延迟要求较低，但是网络对kafka的影响较小

**ISR机制**
> 采用第二种方案之后，设想以下情景：leader 收到数据，所有 follower 都开始同步数据，但有一个 follower，因为某种故障，迟迟不能与 leader 进行同步，那 leader 就要一直等下去，直到它完成同步，才能发送 ack。这个问题怎么解决呢？

> Leader维护了一个动态的集合，称作in-sync replica set(ISR)，意思为和leader保持同步的集合。当ISR集合中的follower同步完成数据后，就给leader发送ack，当ISR中的所有follower都发送完ack后，leader返回给客户端ack，如果follower长时间没有给leader同步数据，那么将会被踢出ISR，进入ISR的标准是以与leader同步的时间作为依据。leader发生故障后，会从ISR中选取新的leader。

**ack应答机制**
> 对于一些不太重要的数据，对数据的可靠性要求不是很高，能够容忍少量数据丢失，所以没必要等ISR中的follower同步成功。
> kafka提供了三种级别可供用户选择，用户根据可靠性和延迟进行权衡

>acks参数配置:
>0:acks = 0代表 producer不等待broker的ack，这一操作提供了一个最低的延迟，broker一接受到还没有写入磁盘就已经返回，当broker故障的时候会丢失数据
>1:ack = 1 代表 producer等待ack，当leader落盘之后就返回，而不需要等待所有的follower落盘，如果在follower同步之前leader发生故障，数据有可能会丢失
>-1: acks = -1 代表 producer等待ack， follower和leader全部落盘成功后才返回ack，但是如果在follower同步之后，broker发送ack之前，leader出现故障，会造成数据重复

![enter description here](https://raw.githubusercontent.com/LazystudentCH/blogImage/master/2020/8/8/[kafka]3.架构深入/1596860986239.png)

